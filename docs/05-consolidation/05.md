**[返回目录](../INDEX.md)** | **[返回本章](./README.md)** | **[上一节](./04.md)** | **[下一节](./06.md)**

# 05.5 离线巩固（Sleep Consolidation）
### 5.1 设计原理

离线巩固在闲置/夜间/对话间隔达到阈值时触发，通过分析当日交互日志，提炼核心记忆，更新慢变量。

### 5.2 巩固流程

#### 5.2.1 统计计算

计算当日 RPE 统计量：

$$
\bar{RPE}_{reward} = \frac{1}{n} \sum_{i=1}^{n} RPE_{reward,i}
$$

$$
\bar{RPE}_{threat} = \frac{1}{n} \sum_{i=1}^{n} RPE_{threat,i}
$$

$$
RPE_{reward,peak} = \max_{i} RPE_{reward,i}
$$

$$
RPE_{threat,peak} = \max_{i} RPE_{threat,i}
$$

$$
duration_{high\_impact} = \sum_{i: |RPE_i| > \tau_{\mathrm{impact,high}}} \Delta t_i
$$

其中：
- $n$：当日交互次数
- \(\tau_{\mathrm{impact,high}}\)：高影响阈值（不展示真实数值）

**参数解释**：
- \(\tau_{\mathrm{impact,high}}\)：控制什么是高影响事件

#### 5.2.2 低影响闲聊处理

低影响闲聊处理策略：

$$
\text{if } |RPE| < \tau_{\mathrm{impact,low}} \text{ then downsample or discard}
$$

其中：
- \(\tau_{\mathrm{impact,low}}\)：低影响阈值（不展示真实数值）

**参数解释**：
- \(\tau_{\mathrm{impact,low}}\)：控制什么是低影响事件

#### 5.2.3 高影响事件处理

高影响事件处理策略：

$$
\text{if } |RPE| > \tau_{\mathrm{impact,high}} \text{ then extract as core memory}
$$

### 5.3 慢变量更新

#### 5.3.1 更新规则

慢变量更新规则：

$$
\mu_{t+1} = \mu_t + \Delta \mu, \quad |\Delta \mu| \le \Delta_{max}
$$

其中：
- $\Delta_{max}$：单次更新最大幅度（不展示真实数值）

**参数解释**：
- $\Delta_{max}$：单次更新最大幅度，控制慢变量更新的速度

#### 5.3.2 消退机制

消退机制：

$$
\text{if } \text{后续多次正向证据出现 then 缓慢回拉}
$$

消退速度：

$$
\Delta \mu_{\mathrm{ext}} = -\eta_{\mathrm{ext}}\cdot \Delta \mu
$$

其中：
- \(\eta_{\mathrm{ext}}\)：消退速率系数（伪变量；不展示真实数值）

**参数解释**：
- \(\eta_{\mathrm{ext}}\)：控制消退速度（符号化）

#### 5.3.3 正负分通道

正负分通道：

$$
\mu_{reward,t+1} = \mu_{reward,t} + \Delta \mu_{reward}, \quad |\Delta \mu_{reward}| \le \Delta_{max}
$$

$$
\mu_{threat,t+1} = \mu_{threat,t} + \Delta \mu_{threat}, \quad |\Delta \mu_{threat}| \le \Delta_{max}
$$

其中：
- $\mu_{reward}$：奖赏通道基线
- $\mu_{threat}$：威胁通道基线

---

**[返回目录](../INDEX.md)** | **[返回本章](./README.md)** | **[上一节](./04.md)** | **[下一节](./06.md)**
